{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import random\n",
    "import copy\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "%matplotlib tk\n",
    "initial_start = time.time()\n",
    "\n",
    "NUM_NODES = 5000\n",
    "MAX_RADIUS_TO_CHECK = 10\n",
    "\n",
    "G = nx.barabasi_albert_graph(NUM_NODES, 3)\n",
    "\n",
    "# G = nx.watts_strogatz_graph(NUM_NODES, 6, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average degree =  5.9964\n",
      "Clustering Coefficient =  0.009256396398105446\n",
      "Average Path Length =  4.040368153630726\n"
     ]
    }
   ],
   "source": [
    "''' Graph Characterization Metrics '''\n",
    "print(\"Average degree = \", 2 * G.number_of_edges() / G.number_of_nodes())\n",
    "print(\"Clustering Coefficient = \", nx.average_clustering(G))\n",
    "print(\"Average Path Length = \", nx.average_shortest_path_length(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def kawai_draw(G, infected=[]) :\n",
    "#     ''' Draw the graph 'G' following the kamada-kawai algorithm\n",
    "#         and coloring the nodes on the 'infected' variable as red\n",
    "#         and the others as green\n",
    "#     '''\n",
    "#     colors = []\n",
    "#     for node in G :\n",
    "#         if node in infected :\n",
    "#             colors.append('red')\n",
    "#         else :\n",
    "#             colors.append('green')\n",
    "#     nx.draw(G, layout=nx.kamada_kawai_layout(G), node_color=colors, node_size = 30, alpha = 0.7)\n",
    "#     plt.show()\n",
    "    \n",
    "# kawai_draw(G)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 124.70673871040344 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "def change_ds(spl_gen, num_nodes, max_radius):\n",
    "    ''' \n",
    "    Transforms 'spl_gen' into the accepted datastructure\n",
    "    by the 'infected_average_by_separation_degree' method\n",
    "    '''\n",
    "    result = []\n",
    "    for n in range(num_nodes):\n",
    "        di_tmp = {}\n",
    "        for entry in spl_gen:  \n",
    "            for radius in range(1, max_radius + 1):\n",
    "                li_tmp = []\n",
    "                for node, dist in entry[1].items():\n",
    "                    if dist == radius:\n",
    "                        li_tmp.append(node)\n",
    "                if li_tmp != []:\n",
    "                    di_tmp[radius - 1] = li_tmp\n",
    "            result.append(copy.copy(di_tmp))\n",
    "            \n",
    "    return result\n",
    "\n",
    "spl = nx.all_pairs_shortest_path_length(G)\n",
    "separation_degrees = change_ds(spl, NUM_NODES, MAX_RADIUS_TO_CHECK)\n",
    "\n",
    "print('Time:', time.time() - start, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def infected_percentage(nodes, infected) :\n",
    "    count = 0\n",
    "    for node in nodes :\n",
    "        if node in infected :\n",
    "            count += 1\n",
    "    \n",
    "    return count / len(nodes)\n",
    "\n",
    "def infected_average_by_separation_degree(G, separation_degrees, infected) :\n",
    "    node_count = {}\n",
    "    percentage_sum = {}\n",
    "    \n",
    "    for node in range(0, len(separation_degrees)) :\n",
    "        if node in infected :\n",
    "            for degree in separation_degrees[node] :\n",
    "                if degree not in percentage_sum.keys() :\n",
    "                    percentage_sum[degree] = 0\n",
    "                    node_count[degree] = 0\n",
    "                percentage_sum[degree] += infected_percentage(separation_degrees[node][degree], infected)\n",
    "                node_count[degree] += 1\n",
    "        \n",
    "    average_by_separation_degree = {}\n",
    "    \n",
    "    for separation_degree in percentage_sum :\n",
    "        average_by_separation_degree[separation_degree] = percentage_sum[separation_degree] / node_count[separation_degree]\n",
    "            \n",
    "    return average_by_separation_degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ndlib\\models\\DiffusionModel.py:161: UserWarning: Graph with less than 100 nodes: a single node will be set as infected\n",
      "  warnings.warn('Graph with less than 100 nodes: a single node will be set as infected')\n"
     ]
    }
   ],
   "source": [
    "import ndlib.models.ModelConfig as mc\n",
    "import ndlib.models.epidemics.SIModel as si\n",
    "import ndlib.models.opinions.VoterModel as vt\n",
    "\n",
    "# Model selection\n",
    "model = si.SIModel(G)\n",
    "#model = vt.VoterModel(G)\n",
    "\n",
    "# Model Configuration\n",
    "cfg = mc.Configuration()\n",
    "cfg.add_model_parameter('beta', 0.05) # probability of infection\n",
    "cfg.add_model_parameter(\"percentage_infected\", 0) # initially infected % (if 0 => 1 infected)\n",
    "model.set_initial_status(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infected count 2534\n",
      "Iterations 29\n",
      "{0: 0.7282744545042684, 1: 0.6554862500208375, 2: 0.6182994298217379, 3: 0.5050649634205433, 4: 0.34342336085082104, 5: 0.1794765044693835, 6: 0.03691678691678697}\n",
      "Time: 283.8887565135956 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "infected = []\n",
    "it_count = 0\n",
    "while len(infected) < NUM_NODES / 2 :\n",
    "    it_count += 1\n",
    "    iteration = model.iteration()\n",
    "    for node, i in iteration['status'].items() :\n",
    "        if i == 1:\n",
    "            infected.append(node)\n",
    "\n",
    "    \n",
    "avg_traits = infected_average_by_separation_degree(G, separation_degrees, infected)\n",
    "infected_count = len(infected)\n",
    "\n",
    "print('Infected count', infected_count)\n",
    "print('Iterations', it_count)\n",
    "print(avg_traits)\n",
    "\n",
    "print('Time:', time.time() - start, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.4871957967898433, 1: 0.5028468193293806, 2: 0.5073724119467996, 3: 0.5080860225806004, 4: 0.5033495621587013, 5: 0.4751906498964554, 6: 0.7733429971008696}\n",
      "Time: 346.8831114768982 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "''' Random distribution of infected nodes '''\n",
    "def simulate_random_infecteds(G_rand, num_nodes, radius_split_rand, num_infects):\n",
    "    '''\n",
    "    Randomly picks the same number of infecteds as in the \n",
    "    non-random model (for each iteration of the spreading)\n",
    "    Returns a list of @infected_average_by_radius lists\n",
    "    '''\n",
    "    random_infected = []\n",
    "    random_not_infected = list(range(0, num_nodes))\n",
    "    \n",
    "    for _ in range(num_infects):\n",
    "        new_inf = random.choice(random_not_infected)\n",
    "        random_infected.append(new_inf)\n",
    "        random_not_infected.remove(new_inf)\n",
    "\n",
    "    avg_trait_sharing_by_radius = infected_average_by_separation_degree(G_rand, separation_degrees, random_infected)\n",
    "    print(avg_trait_sharing_by_radius)    \n",
    "\n",
    "    return (avg_trait_sharing_by_radius, random_infected)\n",
    "\n",
    "avg_random_trait_sharing_by_radius, final_random_infected = simulate_random_infecteds(G, NUM_NODES, separation_degrees, infected_count)\n",
    "\n",
    "print('Time:', time.time() - start, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max separation degree:  7\n",
      "[1.0, 0.6134452362049055, 0.441830056873005, -0.012016188993486207, -0.642088208678216, -1.2576186839006662, -1.924428801398882]\n"
     ]
    }
   ],
   "source": [
    "''' Check maximum degree of separation actually found. '''\n",
    "max_sep_deg = -1\n",
    "for node in separation_degrees:\n",
    "    if max_sep_deg < len(node):\n",
    "        max_sep_deg = len(node)\n",
    "print(\"Max separation degree: \", max_sep_deg)\n",
    "\n",
    "def propensity_by_radius(radius, avg_traits, rand_avg_traits):\n",
    "    return (avg_traits[radius-1] / rand_avg_traits[radius-1]) - 1\n",
    "\n",
    "def all_propensities(max_radius, avg_traits, rand_avg_traits):\n",
    "    all_propensities = []\n",
    "    for r in range(1, max_radius + 1):\n",
    "        all_propensities.append(propensity_by_radius(r, avg_traits, rand_avg_traits))\n",
    "    return all_propensities\n",
    "\n",
    "def normalized_propensities(max_radius, all_propensities):\n",
    "    normalized_propensities = []\n",
    "    for r in range(max_radius):\n",
    "        normalized_propensities.append(all_propensities[r] / all_propensities[0])\n",
    "    \n",
    "    return normalized_propensities\n",
    "\n",
    "all_props = all_propensities(max_sep_deg, avg_traits, avg_random_trait_sharing_by_radius) \n",
    "print(normalized_propensities(max_sep_deg, all_props))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg nodes per degree of separation: [5.9964, 96.9672, 909.848, 2698.7552, 1251.3406, 45.5268, 0.91]\n",
      "Total time: 864.9466552734375\n"
     ]
    }
   ],
   "source": [
    "''' Count total nodes per degree of separation. '''\n",
    "total_nodes_per_sep_deg = [0 for _ in range(max_sep_deg)]\n",
    "for node in separation_degrees :\n",
    "    for dist in node:\n",
    "        total_nodes_per_sep_deg[dist] += len(node[dist])\n",
    "\n",
    "''' Calculate average nodes per degree of separation.\n",
    "    Note that values can be < 0 because not every node\n",
    "    has the same number of maximum separation degrees. '''\n",
    "avg_nodes_per_sep_deg = []\n",
    "for total_nodes in total_nodes_per_sep_deg:\n",
    "    avg_nodes_per_sep_deg.append(total_nodes/len(separation_degrees))\n",
    "\n",
    "print(\"Avg nodes per degree of separation:\", avg_nodes_per_sep_deg)\n",
    "\n",
    "print(\"Total time:\", time.time() - initial_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport pickle\\n\\nwith open('2000_nodes_scale_free.graph', 'wb') as f:  # Python 3: open(..., 'wb')\\n    pickle.dump(G, f)\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving graph to file\n",
    "'''\n",
    "import pickle\n",
    "\n",
    "with open('2000_nodes_scale_free.graph', 'wb') as f:  # Python 3: open(..., 'wb')\n",
    "    pickle.dump(G, f)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport pickle\\n\\nwith open('2000_nodes_scale_free.graph', 'rb') as f:  # Python 3: open(..., 'rb')\\n    Gtest = pickle.load(f)\\n\\nprint(2 * Gtest.number_of_edges() / Gtest.number_of_nodes())\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading graph from file\n",
    "'''\n",
    "import pickle\n",
    "\n",
    "with open('2000_nodes_scale_free.graph', 'rb') as f:  # Python 3: open(..., 'rb')\n",
    "    Gtest = pickle.load(f)\n",
    "\n",
    "print(2 * Gtest.number_of_edges() / Gtest.number_of_nodes())\n",
    "'''\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
